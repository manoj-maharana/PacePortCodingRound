# -*- coding: utf-8 -*-
"""Rapidlab_Assignment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cf5E34Z14lHevjuWC7X0N54t3mozKPdz
"""

from google.colab import drive
drive.mount('/content/gdrive/')

"""###Data Preparation"""

import pandas as pd

# Load the dataset
fashion_df = pd.read_csv('/content/gdrive/MyDrive/Dataset/fashion.csv')

# Preview the dataset
print(fashion_df.head())

# Update the ImageURL column to point to the correct paths
fashion_df['ImageURL'] = '/content/gdrive/MyDrive/Dataset/images/' + fashion_df['Image']

# Verify the updated paths
print(fashion_df['ImageURL'].head())

!ls '/content/gdrive/MyDrive/Dataset/images/'

import requests
import os
import time

# Specify the folder on your Google Drive where you want to save the images
save_folder = '/content/gdrive/MyDrive/Dataset/images/'

# Create the directory if it doesn't exist
os.makedirs(save_folder, exist_ok=True)

# Load the original CSV file (before any modifications to the ImageURL column)
original_fashion_df = pd.read_csv('/content/gdrive/MyDrive/Dataset/fashion.csv')

# Track the number of downloaded and skipped images
downloaded_count = 0
skipped_count = 0

# Download and save all images
for idx, row in original_fashion_df.iterrows():
    img_url = row['ImageURL']
    img_name = row['Image']
    img_path = os.path.join(save_folder, img_name)

    # Check if the image file already exists
    if os.path.exists(img_path):
        skipped_count += 1
        continue

    # Attempt to download the image with retries
    max_retries = 3
    for attempt in range(max_retries):
        try:
            response = requests.get(img_url)
            with open(img_path, 'wb') as file:
                file.write(response.content)
            downloaded_count += 1
            break
        except requests.ConnectionError:
            print(f"Connection error for {img_url}. Retrying...")
            time.sleep(5) # Wait for 5 seconds before retrying
    else:
        print(f"Failed to download {img_url} after {max_retries} attempts.")

# Report the results
print(f"Downloaded {downloaded_count} new images to {save_folder}")
print(f"Skipped {skipped_count} images that already exist")

import os

# Specify the folder on your Google Drive where the images are saved
image_folder = '/content/gdrive/MyDrive/Dataset/images/'

# List all files in the folder
image_files = os.listdir(image_folder)

# Count the number of image files (assuming they have .jpg extension)
image_count = sum([file.endswith('.jpg') for file in image_files])

print(f"There are {image_count} images in the folder {image_folder}")

"""###Image Analysis"""

# Modifying the code for image preprocessing and feature extraction to make it more efficient

# Defining a function to extract features from images using MobileNet
from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input
from tensorflow.keras.preprocessing.image import img_to_array, load_img
import numpy as np

def extract_features(image_paths, batch_size=32):
    # Load pre-trained MobileNet model
    mobilenet_model = MobileNet(weights='imagenet', include_top=False)

    features_list = []

    # Process images in batches
    for i in range(0, len(image_paths), batch_size):
        batch_paths = image_paths[i:i+batch_size]
        images = [load_img(image_path, target_size=(224, 224)) for image_path in batch_paths]
        images_array = np.array([img_to_array(img) for img in images])
        images_array = preprocess_input(images_array)

        # Predict features using MobileNet
        batch_features = mobilenet_model.predict(images_array)
        batch_features_flatten = [feature.reshape(-1) for feature in batch_features]
        features_list.extend(batch_features_flatten)

    return np.array(features_list)

# Example usage (assuming fashion_df['ImageURL'] contains the image paths)
X = extract_features(fashion_df['ImageURL'])

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

def encode_labels(column):
    label_encoder = LabelEncoder()
    labels = label_encoder.fit_transform(fashion_df[column])
    return to_categorical(labels), label_encoder

y_category, label_encoder_category = encode_labels('Category')
y_subcategory, label_encoder_subcategory = encode_labels('SubCategory')
y_color, label_encoder_color = encode_labels('Colour')
y_product_type, label_encoder_product_type = encode_labels('ProductType')
y_usage, label_encoder_usage = encode_labels('Usage')

def split_data(X, y):
    return train_test_split(X, y, test_size=0.2, random_state=42)

# Split the data
X_train, X_test, y_train_category, y_test_category = split_data(X, y_category)
_, _, y_train_subcategory, y_test_subcategory = split_data(X, y_subcategory)
_, _, y_train_color, y_test_color = split_data(X, y_color)
_, _, y_train_product_type, y_test_product_type = split_data(X, y_product_type)
_, _, y_train_usage, y_test_usage = split_data(X, y_usage)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
import os
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping

from tensorflow.keras.layers import Dropout
from tensorflow.keras.callbacks import EarlyStopping

def create_model(y):
    model = Sequential()
    model.add(Dense(512, activation='relu', input_shape=(X_train.shape[1],)))
    model.add(Dropout(0.3)) # Dropout layer to prevent overfitting
    model.add(Dense(256, activation='relu'))
    model.add(Dropout(0.3)) # Dropout layer to prevent overfitting
    model.add(Dense(y.shape[1], activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def train_and_save(model, y_train, model_name):
    early_stopping = EarlyStopping(monitor='val_loss', patience=5)
    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1, callbacks=[early_stopping])
    model.save(os.path.join('models', model_name))

# Training
train_and_save(create_model(y_category), y_train_category, 'model_category.h5')

train_and_save(create_model(y_subcategory), y_train_subcategory, 'model_subcategory.h5')
train_and_save(create_model(y_color), y_train_color, 'model_color.h5')

train_and_save(create_model(y_product_type), y_train_product_type, 'model_product_type.h5')
train_and_save(create_model(y_usage), y_train_usage, 'model_usage.h5')

from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import numpy as np

mobilenet_model = MobileNet(weights='imagenet', include_top=False)

def get_image_features(image_path):
    image = load_img(image_path, target_size=(224, 224))
    image = img_to_array(image)
    image = np.expand_dims(image, axis=0)
    image = preprocess_input(image)
    features = mobilenet_model.predict(image)
    return features.reshape(-1)  # Flatten the features

from tensorflow.keras.models import load_model
import glob
import os
def load_all_models():
    models = {}
    models['category'] = load_model('models/model_category.h5')
    models['subcategory'] = load_model('models/model_subcategory.h5')
    models['color'] = load_model('models/model_color.h5')
    models['product_type'] = load_model('models/model_product_type.h5')
    models['usage'] = load_model('models/model_usage.h5')
    return models

import numpy as np

# ...

def predict_details(image_path, models):
    features = get_image_features(image_path)
    features = features.reshape(1, -1)

    details = {}
    details['Category'] = label_encoder_category.inverse_transform([np.argmax(models['category'].predict(features))])[0]
    details['SubCategory'] = label_encoder_subcategory.inverse_transform([np.argmax(models['subcategory'].predict(features))])[0]
    details['Color'] = label_encoder_color.inverse_transform([np.argmax(models['color'].predict(features))])[0]
    details['ProductType'] = label_encoder_product_type.inverse_transform([np.argmax(models['product_type'].predict(features))])[0]
    details['Usage'] = label_encoder_usage.inverse_transform([np.argmax(models['usage'].predict(features))])[0]

    return details


models = load_all_models()
test_images_folder = '/content/gdrive/MyDrive/Dataset/test_images/test_images/'
for image_path in glob.glob(os.path.join(test_images_folder, '*.jpg')):
    details = predict_details(image_path, models)
    print(f"Details for {os.path.basename(image_path)}:")
    for key, value in details.items():
        print(f"{key}: {value}")
    print()

"""###Key Detail Prediction"""

import shutil
import os

source_folder = '/content/models/'
destination_folder = '/content/gdrive/MyDrive/Dataset'

# Make sure the destination folder exists
os.makedirs(destination_folder, exist_ok=True)

# List all files with .h5 extension in the source folder
model_files = [f for f in os.listdir(source_folder) if f.endswith('.h5')]

# Copy each file to the destination folder
for model_file in model_files:
    source_path = os.path.join(source_folder, model_file)
    destination_path = os.path.join(destination_folder, model_file)
    shutil.copy(source_path, destination_path)

print("Models copied successfully!")

models = load_all_models()

from sklearn.metrics import pairwise_distances

def get_similar_products_cnn(image_path, num_results):
    # Get the features for the input image using your existing method
    query_features = extract_features([image_path])

    # Compute pairwise distances between the query and all other feature vectors
    pairwise_dist = pairwise_distances(X, query_features)

    # Get the indices of the top similar products
    indices = np.argsort(pairwise_dist.flatten())[0:num_results]

    # Get the details of the recommended products from your DataFrame (replace with your DataFrame name)
    recommended_products = fashion_df.loc[indices]

    return recommended_products

# Example usage
#image_path = "path_to_your_image.jpg"
#num_results = 5
#recommended_products = get_similar_products_cnn(image_path, num_results)

# Print or display the recommended products
#for idx, product in recommended_products.iterrows():
    #print(f"Product ID: {product['ProductId']}, Title: {product['ProductTitle']}, Image URL: {product['ImageURL']}")

from PIL import Image as PILImage
from IPython.display import display

test_images_folder = '/content/gdrive/MyDrive/Dataset/test_images/test_images'
image_paths = glob.glob(test_images_folder + '/*.jpg')  # Adjust the file extension if necessary
#image_paths = '/content/gdrive/MyDrive/Dataset/test_images/test_images/3.jpg'
num_results = 5

for image_path in image_paths:
    recommended_products = get_similar_products_cnn(image_path, num_results)

    print(f"Recommendations for {image_path}:")
    for idx, product in recommended_products.iterrows():
        print(f"Product ID: {product['ProductId']}, Title: {product['ProductTitle']}")
        img = PILImage.open(product['ImageURL'])
        img = img.resize((224, 224))
        display(img)
    print()

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical

# Prepare the product information data
product_titles = fashion_df['ProductTitle'].tolist()

# Text preprocessing and tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(product_titles)
total_words = len(tokenizer.word_index) + 1

# Convert text to sequences
input_sequences = []
for line in product_titles:
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

# Pad sequences
max_sequence_length = max([len(x) for x in input_sequences])
input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')

# Create predictors and labels
X, y = input_sequences[:, :-1], input_sequences[:, -1]

# One-hot encode the labels
y = to_categorical(y, num_classes=total_words)

# Model architecture
model = Sequential()
model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))
model.add(LSTM(200))
model.add(Dropout(0.2))
model.add(Dense(total_words, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=100, verbose=1)

# Generate product descriptions
def generate_product_description(seed_text, num_words):
    for _ in range(num_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')
        predicted_token = np.argmax(model.predict(token_list), axis=-1)
        output_word = tokenizer.index_word[predicted_token[0]]
        seed_text += " " + output_word
    return seed_text

# Generate description for a given seed text
seed_text = "Stylish Women's Dress"
generated_description = generate_product_description(seed_text, num_words=20)
print("Generated Description:", generated_description)

import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
from tensorflow.keras.utils import to_categorical

# Prepare the product information data
product_titles = fashion_df['ProductTitle'].tolist()

# Text preprocessing and tokenization
tokenizer = Tokenizer()
tokenizer.fit_on_texts(product_titles)
total_words = len(tokenizer.word_index) + 1

# Convert text to sequences
input_sequences = []
for line in product_titles:
    token_list = tokenizer.texts_to_sequences([line])[0]
    for i in range(1, len(token_list)):
        n_gram_sequence = token_list[:i+1]
        input_sequences.append(n_gram_sequence)

# Pad sequences
max_sequence_length = max([len(x) for x in input_sequences])
input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')

# Create predictors and labels
X, y = input_sequences[:, :-1], input_sequences[:, -1]

# One-hot encode the labels
y = to_categorical(y, num_classes=total_words)

# Model architecture
model = Sequential()
model.add(Embedding(total_words, 100, input_length=max_sequence_length-1))
model.add(Bidirectional(LSTM(200, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01))))
model.add(Dropout(0.2))
model.add(Dense(total_words, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=100, verbose=1)

# Generate product descriptions
def generate_product_description(seed_text, num_words):
    for _ in range(num_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')
        predicted_token = np.argmax(model.predict(token_list), axis=-1)
        output_word = tokenizer.index_word[predicted_token[0]]
        seed_text += " " + output_word
    return seed_text

# Generate description for a given seed text
seed_text = "Stylish Women's Dress"
generated_description = generate_product_description(seed_text, num_words=20)
print("Generated Description:", generated_description)